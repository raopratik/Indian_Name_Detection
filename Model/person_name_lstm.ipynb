{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "synthesized_data = pd.DataFrame(columns=[['sentence', 'v0', 'v1', 'v2', 'v3', 'v4','v5','v6'\n",
    "                                         ,'v7','v8','v9']])\n",
    "#for i in range(1000):\n",
    "#    synthesized_data = pd.concat([synthesized_data,pd.DataFrame({'sentence': ('My name is pratik jayarao'),\n",
    "                                                               \n",
    "y_list = []\n",
    "for i in range(1000):\n",
    "    y_list.append([[1,0],[1,0],[1,0],[0,1],[0,1],[1,0],[1,0],[1,0],[0,1],[0,1]])\n",
    "\n",
    "y_list = np.array(y_list)\n",
    "print(y_list.shape)\n",
    "#with open('person_name_git4.txt','a+') as my_file:\n",
    "#    for i in range(len(synthesized_data)):,\n",
    "#        my_file.write(synthesized_data.iloc[i]['sentence']+\"\\n\")\n",
    "\n",
    "import gensim\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "#sentences = gensim.models.word2vec.LineSentence(\"person_name_git4.txt\")\n",
    "#print(\"sentences\")\n",
    "#model = gensim.models.word2vec.Word2Vec(sentences,sample = 0.001, sg = 1, workers = 4, negative = 20, window = 10, seed = 1, alpha = 0.025, min_count = 0, min_alpha = 0.0001, size = 100)\n",
    "#print(\"model\")\n",
    "#model.save('person_name_vectors')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vectors = gensim.models.Word2Vec.load('person_name_vectors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordVectors = []\n",
    "for word in word_vectors.wv.index2word:\n",
    "    wordVectors.append(word_vectors.wv[word])\n",
    "wordVectors = np.array(wordVectors)\n",
    "wordsList = word_vectors.wv.index2word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "[3 4 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pratik/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "maxSeqLength = 10 #Maximum length of sentence\n",
    "numDimensions = 100 #Dimensions for each word vector\n",
    "firstSentence = np.zeros((maxSeqLength), dtype='int32')\n",
    "firstSentence[0] = wordsList.index(\"pratik\")\n",
    "firstSentence[1] = wordsList.index(\"jayarao\")\n",
    "print(firstSentence.shape)\n",
    "print(firstSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 100)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(tf.nn.embedding_lookup(wordVectors,firstSentence).eval().shape)\n",
    "\n",
    "train = synthesized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#numFiles = len(train)\n",
    "#maxSeqLength = 10\n",
    "#ids = np.zeros((numFiles, maxSeqLength), dtype='int32')\n",
    "#fileCounter = 0\n",
    "#indexCounter = 0\n",
    "\n",
    "#for line in train['sentence']:\n",
    "#    cleanedLine = cleanSentences(str(line))\n",
    "#    split = line.split()\n",
    "#    indexCounter = 0\n",
    "    \n",
    "#    for word in split:\n",
    "       # print(indexCounter)\n",
    "#        try:\n",
    "#            ids[fileCounter][indexCounter] = wordsList.index(word)\n",
    "#        except ValueError:\n",
    "#            ids[fileCounter][indexCounter] = len(wordsList)-2 #Vector for unkown words\n",
    "#        indexCounter = indexCounter + 1\n",
    "#        if indexCounter >= maxSeqLength:\n",
    "#            break\n",
    "#    fileCounter = fileCounter + 1 \n",
    "#    print(fileCounter/numFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.save('person_name_ids',ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = np.load('person_name_ids.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 10), (0, 11), (0, 10))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids.shape, train.shape, train[['v0', 'v1', 'v2', 'v3', 'v4','v5','v6'\n",
    "                                         ,'v7','v8','v9']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>v0</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sentence, v0, v1, v2, v3, v4, v5, v6, v7, v8, v9]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchSize = 100\n",
    "lstmUnits = 64\n",
    "numClasses = 2\n",
    "epochs = 10\n",
    "maxSeqLength = 10\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(ids,y_list, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTrainBatch(j):\n",
    "    i = j*batchSize\n",
    "    arr = X_train[i:i+batchSize]\n",
    "    labels = y_train[i:i+batchSize]\n",
    "    \n",
    "    return arr, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTestBatch(j):\n",
    "    i = j*batchSize\n",
    "    arr = X_test[i:i+batchSize]\n",
    "    labels =   y_test[i:i+batchSize]\n",
    "    return arr, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getTrainBatch(1)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "labels = tf.placeholder(tf.float32, [batchSize, maxSeqLength, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, maxSeqLength])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordVectors = tf.convert_to_tensor(wordVectors, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = tf.placeholder(shape = (batchSize,maxSeqLength,numDimensions), dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(wordVectors,input_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fw_cell3 = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.BasicLSTMCell(lstmUnits, state_is_tuple=True) for _ in range(2)])\n",
    "bw_cell3 = tf.nn.rnn_cell.MultiRNNCell([ tf.nn.rnn_cell.BasicLSTMCell(lstmUnits, state_is_tuple=True) for _ in range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs,value2 = tf.nn.bidirectional_dynamic_rnn(fw_cell3, bw_cell3,data,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = tf.concat(outputs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([lstmUnits*2,numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[batchSize,maxSeqLength,numClasses]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = (tf.tensordot(outputs, weight, axes=((2,),(0,))) + bias)\n",
    "correctPred = tf.equal(tf.argmax(prediction,axis=2), tf.argmax(labels,axis=2))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10, 128) (128, 2) (100, 10, 2) (100, 10, 2)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    o,w,b,p = sess.run([outputs,weight,bias,prediction],feed_dict={input_data: X_train[:100], labels: y_train[:100]})\n",
    "    print(np.array(o).shape,np.array(w).shape,np.array(b).shape,np.array(p).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "epoch:  1\n",
      "epoch:  2\n",
      "epoch:  3\n",
      "epoch:  4\n",
      "epoch:  5\n",
      "epoch:  6\n",
      "epoch:  7\n",
      "epoch:  8\n",
      "epoch:  9\n",
      "[[[ 14.949078  -13.304953 ]\n",
      "  [ 10.696237  -10.12192  ]\n",
      "  [  3.3658986  -3.5698216]\n",
      "  ...\n",
      "  [  4.0793324  -4.1829925]\n",
      "  [ -3.920346    3.7513685]\n",
      "  [-11.193136   10.928375 ]]\n",
      "\n",
      " [[ 14.949078  -13.304953 ]\n",
      "  [ 10.696237  -10.12192  ]\n",
      "  [  3.3658986  -3.5698216]\n",
      "  ...\n",
      "  [  4.0793324  -4.1829925]\n",
      "  [ -3.920346    3.7513685]\n",
      "  [-11.193136   10.928375 ]]\n",
      "\n",
      " [[ 14.949078  -13.304953 ]\n",
      "  [ 10.696237  -10.12192  ]\n",
      "  [  3.3658986  -3.5698216]\n",
      "  ...\n",
      "  [  4.0793324  -4.1829925]\n",
      "  [ -3.920346    3.7513685]\n",
      "  [-11.193136   10.928375 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 14.949078  -13.304953 ]\n",
      "  [ 10.696237  -10.12192  ]\n",
      "  [  3.3658986  -3.5698216]\n",
      "  ...\n",
      "  [  4.0793324  -4.1829925]\n",
      "  [ -3.920346    3.7513685]\n",
      "  [-11.193136   10.928375 ]]\n",
      "\n",
      " [[ 14.949078  -13.304953 ]\n",
      "  [ 10.696237  -10.12192  ]\n",
      "  [  3.3658986  -3.5698216]\n",
      "  ...\n",
      "  [  4.0793324  -4.1829925]\n",
      "  [ -3.920346    3.7513685]\n",
      "  [-11.193136   10.928375 ]]\n",
      "\n",
      " [[ 14.949078  -13.304953 ]\n",
      "  [ 10.696237  -10.12192  ]\n",
      "  [  3.3658986  -3.5698216]\n",
      "  ...\n",
      "  [  4.0793324  -4.1829925]\n",
      "  [ -3.920346    3.7513685]\n",
      "  [-11.193136   10.928375 ]]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(\"epoch:  \"+str(i))\n",
    "    #Next Batch of reviews\n",
    "    for j in range(len(X_train)//batchSize):\n",
    "        nextBatch, nextBatchLabels = getTrainBatch(j);\n",
    "        #print(j/2)\n",
    "        _,pred,lab = sess.run([optimizer,prediction,labels], {input_data: nextBatch, labels: nextBatchLabels})\n",
    "\n",
    "    #Write summary to Tensorboard\n",
    "        if (j % 5 == 0):\n",
    "            summary = sess.run(merged, {input_data: nextBatch, labels: nextBatchLabels})\n",
    "            writer.add_summary(summary, j)\n",
    "\n",
    "        #Save the network every 10,000 training iterations\n",
    "        if (j % 50 == 0 and j != 0):\n",
    "            save_path = saver.save(sess, \"models/pretrained_lstm.ckpt\", global_step=i)\n",
    "            print(\"saved to %s\" % save_path)\n",
    "print((np.array(pred)))\n",
    "x3 = np.array(lab)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for this batch: 100.0\n",
      "Accuracy for this batch: 100.0\n"
     ]
    }
   ],
   "source": [
    "test_batches = 2\n",
    "for j in range(test_batches):\n",
    "    nextBatch, nextBatchLabels = getTestBatch(j);\n",
    "    print(\"Accuracy for this batch:\", (sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[ 15.984614 , -18.476969 ],\n",
    " [ 11.581611 , -13.3633375],\n",
    " [  4.762972 ,  -5.3671947],\n",
    " [ -3.291655 ,   3.5226593],\n",
    " [ -3.8651543 ,  3.9896889],\n",
    " [  4.91325   , -4.6390204],\n",
    " [  9.824387  , -9.47608  ],\n",
    " [  5.9091616 , -5.683087 ],\n",
    " [ -3.9726372 ,  3.8681452],\n",
    " [-12.435596  , 12.365538 ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 0, 0, 1, 1]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3.argmax(axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-f0693a5e9147>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x2' is not defined"
     ]
    }
   ],
   "source": [
    "x2.argmax(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
